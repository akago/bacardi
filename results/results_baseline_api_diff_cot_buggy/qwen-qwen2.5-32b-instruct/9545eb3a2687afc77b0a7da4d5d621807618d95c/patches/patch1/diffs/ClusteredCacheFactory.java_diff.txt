1,16d0
< /*
<  * Copyright (C) 2007-2009 Jive Software. All rights reserved.
<  *
<  * Licensed under the Apache License, Version 2.0 (the "License");
<  * you may not use this file except in compliance with the License.
<  * You may obtain a copy of the License at
<  *
<  *     http://www.apache.org/licenses/LICENSE-2.0
<  *
<  * Unless required by applicable law or agreed to in writing, software
<  * distributed under the License is distributed on an "AS IS" BASIS,
<  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<  * See the License for the specific language governing permissions and
<  * limitations under the License.
<  */
< 
18a3,4
> import com.hazelcast.cluster.Cluster;
> import com.hazelcast.cluster.Member;
24d9
< import com.hazelcast.config.MemcacheProtocolConfig;
27c12
< import com.hazelcast.core.Cluster;
---
> import com.hazelcast.config.MemcacheProtocolConfig;
30c15,20
< import com.hazelcast.core.Member;
---
> import com.hazelcast.core.LifecycleService;
> import com.hazelcast.core.MembershipListener;
> import com.hazelcast.core.LifecycleEvent;
> import com.hazelcast.core.LifecycleEvent.LifecycleState;
> import com.hazelcast.core.LifecycleListener;
> import com.hazelcast.core.MemberSelector;
99d88
<         .setChronoUnit(ChronoUnit.SECONDS)
155c144,667
<      * Keeps that running state. Initial state is stopped.
---
>      * Gets the pseudo-synchronized time from the cluster. While the cluster members may
>      * have varying system times, this method is expected to return a timestamp that is
>      * synchronized (or nearly so; best effort) across the cluster.
>      *
>      * @return Synchronized time for all cluster members
>      */
>     @Override
>     public long getClusterTime() {
>         return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();
>     }
> 
>     /*
>      * Execute the given task on the other (non-local) cluster members.
>      * Note that this method does not provide the result set for the given
>      * task, as the task is run asynchronously across the cluster.
>      */
>     @Override
>     public void doClusterTask(final ClusterTask<?> task) {
> 
>         if (cluster == null) {
>             return;
>         }
>         final Set<Member> members = new HashSet<>();
>         final Member current = cluster.getLocalMember();
>         for (final Member member : cluster.getMembers()) {
>             if (!member.getUuid().equals(current.getUuid())) {
>                 members.add(member);
>             }
>         }
> 
>         if (!members.isEmpty()) {
>             // Asynchronously execute the task on the other cluster members
>             logger.debug("Executing asynchronous MultiTask: " + task.getClass().getName());
>             checkForPluginClassLoader(task);
>             hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);
>         } else {
>             logger.debug("No cluster members selected for cluster task " + task.getClass().getName());
>         }
>     }
> 
>     /*
>      * Execute the given task on the given cluster member.
>      * Note that this method does not provide the result set for the given
>      * task, as the task is run asynchronously across the cluster.
>      */
>     @Override
>     public void doClusterTask(final ClusterTask<?> task, final byte[] nodeID) {
>         if (cluster == null) {
>             return;
>         }
>         final Member member = getMember(nodeID);
>         // Check that the requested member was found
>         if (member != null) {
>             // Asynchronously execute the task on the target member
>             logger.debug("Executing asynchronous DistributedTask: " + task.getClass().getName());
>             checkForPluginClassLoader(task);
>             hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMember(new CallableTask<>(task), member);
>         } else {
>             final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8));
>             logger.warn(msg);
>             throw new IllegalArgumentException(msg);
>         }
>     }
> 
>     /*
>      * Execute the given task on the designated cluster members.
>      * Note that this method blocks for up to MAX_CLUSTER_EXECUTION_TIME
>      * (seconds) per member until the task is run on all members.
>      */
>     @Override
>     public <T> Collection<T> doSynchronousClusterTask(final ClusterTask<T> task, final boolean includeLocalMember) {
>         if (cluster == null) {
>             return Collections.emptyList();
>         }
>         final Set<Member> members = new HashSet<>();
>         final Member current = cluster.getLocalMember();
>         for (final Member member : cluster.getMembers()) {
>             if (includeLocalMember || (!member.getUuid().equals(current.getUuid()))) {
>                 members.add(member);
>             }
>         }
>         final Collection<T> result = new ArrayList<>();
>         if (!members.isEmpty()) {
>             // Asynchronously execute the task on the other cluster members
>             try {
>                 logger.debug("Executing MultiTask: " + task.getClass().getName());
>                 checkForPluginClassLoader(task);
>                 final Map<Member, ? extends Future<T>> futures = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);
>                 long nanosLeft = TimeUnit.SECONDS.toNanos(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds() * members.size());
>                 for (final Future<T> future : futures.values()) {
>                     final long start = System.nanoTime();
>                     result.add(future.get(nanoLeft, TimeUnit.NANOSECONDS));
>                     nanosLeft = nanosLeft - (System.nanoTime() - start);
>                 }
>             } catch (final TimeoutException te) {
>                 logger.error("Failed to execute cluster task within " + StringUtils.getFullElapsedTime(MAX_CLUSTER_EXECUTION_TIME.getValue()), te);
>             } catch (final Exception e) {
>                 logger.error("Failed to execute cluster task", e);
>             }
>         } else {
>             logger.debug("No cluster members selected for cluster task " + task.getClass().getName());
>         }
>         return result;
>     }
> 
>     /*
>      * Execute the given task on the designated cluster member.
>      * Note that this method blocks for up to MAX_CLUSTER_EXECUTION_TIME
>      * (seconds) until the task is run on the given member.
>      */
>     @Override
>     public <T> T doSynchronousClusterTask(final ClusterTask<T> task, final byte[] nodeID) {
>         if (cluster == null) {
>             return null;
>         }
>         final Member member = getMember(nodeID);
>         T result = null;
>         // Check that the requested member was found
>         if (member != null) {
>             // Asynchronously execute the task on the target member
>             logger.debug("Executing DistributedTask: " + task.getClass().getName());
>             checkForPluginClassLoader(task);
>             try {
>                 final Future<T> future = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMember(new CallableTask<>(task), member);
>                 result = future.get(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds(), TimeUnit.SECONDS);
>                 logger.trace("DistributedTask result: {}", result);
>             } catch (final TimeoutException te) {
>                 logger.error("Failed to execute cluster task within " + MAX_CLUSTER_EXECUTION_TIME + " seconds", te);
>             } catch (final Exception e) {
>                 logger.error("Failed to execute cluster task", e);
>             }
>         } else {
>             final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8));
>             logger.warn(msg);
>             throw new IllegalArgumentException(msg);
>         }
>         return result;
>     }
> 
>     @Override
>     public ClusterNodeInfo getClusterNodeInfo(final byte[] nodeID) {
>         if (cluster == null) {
>             return null;
>         }
>         ClusterNodeInfo result = null;
>         final Member member = getMember(nodeID);
>         if (member != null) {
>             result = new HazelcastClusterNodeInfo(member, cluster.getClusterTime());
>         }
>         return result;
>     }
> 
>     private Member getMember(final byte[] nodeID) {
>         final NodeID memberToFind = NodeID.getInstance(nodeID);
>         for (final Member member : cluster.getMembers()) {
>             if (memberToFind.equals(getNodeID(member))) {
>                 return member;
>             }
>         }
>         return null;
>     }
> 
>     @Override
>     public void updateCacheStats(final Map<String, Cache> caches) {
>         if (!caches.isEmpty() && cluster != null) {
>             // Create the cacheStats map if necessary.
>             if (cacheStats == null) {
>                 cacheStats = hazelcast.getMap("opt-$cacheStats");
>             }
>             final String uid = getNodeID(cluster.getLocalMember()).toString();
>             final Map<String, long[]> stats = new HashMap<>();
>             for (final String cacheName : caches.keySet()) {
>                 final Cache cache = caches.get(cacheName);
>                 // The following information is published:
>                 // current size, max size, num elements, cache
>                 // hits, cache misses.
>                 final long[] info = new long[5];
>                 info[0] = cache.getLongCacheSize();
>                 info[1] = cache.getMaxCacheSize();
>                 info[2] = cache.size();
>                 info[3] = cache.getCacheHits();
>                 info[4] = cache.getCacheMisses();
>                 stats.put(cacheName, info);
>             }
>             // Publish message
>             cacheStats.put(uid, stats);
>         }
>     }
> 
>     @Override
>     public String getPluginName() {
>         return PLUGIN_NAME;
>     }
> 
>     @Override
>     public Lock getLock(final Object key, Cache cache) {
>         if (cache instanceof CacheWrapper) {
>             cache = ((CacheWrapper) cache).getWrappedCache();
>         }
>         // TODO: Update CacheFactoryStrategy so the signature is getLock(final Serializable key, Cache<Serializable, Serializable> cache)
>         @SuppressWarnings("unchecked") final ClusterLock clusterLock = new ClusterLock((Serializable) key, (ClusteredCache<Serializable, ?>) cache);
>         return clusterLock;
>     }
> 
>     /**
>      * ClusterTasks that are executed should not be provided by a plugin. These will cause issues related to class
>      * loading when the providing plugin is reloaded. This method verifies if an instance of a task is
>      * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is
>      * limited by a time interval.
>      *
>      * @param o the instance for which to verify the class loader
>      * @see <a href="https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>
>      */
>     protected <T extends ClusterTask<?>> void checkForPluginClassLoader(final T o) {
>         if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader
>             && !pluginClassLoaderWarnings.containsKey(o.getClass().getName()) )
>         {
>             // Try to determine what plugin loaded the offending class.
>             String pluginName = null;
>             try {
>                 final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();
>                 for (final Plugin plugin : plugins) {
>                     final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);
>                     if (o.getClass().getClassLoader().equals(pluginClassloader)) {
>                         pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);
>                         break;
>                     }
>                 }
>             } catch (Exception e) {
>                 logger.debug("An exception occurred while trying to determine the plugin class loader that loaded an instance of {}", o.getClass(), e);
>             }
>             logger.warn("An instance of {} that is executed as a cluster task. This will cause issues when reloading " +
>                     "the plugin that provides this class. The plugin implementation should be modified.",
>                 pluginName != null ? o.getClass() + " (provided by plugin " + pluginName + ")" : o.getClass());
>             pluginClassLoaderWarnings.put(o.getClass().name(), Instant.now()); // Note that this Instant is unused.
>         }
>     }
> 
>     private static class ClusterLock implements Lock {
> 
>         private final Serializable key;
>         private final ClusteredCache<Serializable, ?> cache;
> 
>         ClusterLock(final Serializable key, final ClusteredCache<Serializable, ?> cache) {
>             this.key = key;
>             this.cache = cache;
>         }
> 
>         @Override
>         public void lock() {
>             cache.lock(key, -1);
>         }
> 
>         @Override
>         public void lockInterruptibly() {
>             cache.lock(key, -1);
>         }
> 
>         @Override
>         public boolean tryLock() {
>             return cache.lock(key, 0);
>         }
> 
>         @Override
>         public boolean tryLock(final long time, final TimeUnit unit) {
>             return cache.lock(key, unit.toMillis(time));
>         }
> 
>         @Override
>         public void unlock() {
>             cache.unlock(key);
>         }
> 
>         @Override
>         public Condition newCondition() {
>             throw new UnsupportedOperationException();
>         }
>     }
> 
>     private static class CallableTask<V> implements Callable<V>, Serializable {
>         private static final long serialVersionUID = -8761271979427214681L;
>         private final ClusterTask<V> task;
> 
>         CallableTask(final ClusterTask<V> task) {
>             this.task = task;
>         }
> 
>         @Override
>         public V call() {
>             try {
>                 task.run();
>                 logger.trace("CallableTask[{}] result: {}", task.getClass().name(), task.getResult());
>                 return task.getResult();
>             } catch (final Exception e) {
>                 logger.error("Unexpected exception running CallableTask[{}]", task.getClass().name(), e);
>                 throw e;
>             }
>         }
>     }
> 
>     private enum State {
>         stopped,
>         starting,
>         started
>     }
> 
>     public static NodeID getNodeID(final Member member) {
>         return NodeID.getInstance(member.getAttribute(HazelcastClusterNodeInfo.HOST_NAME_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));
>     }
> 
>     static void fireLeftClusterAndWaitToComplete(final Duration timeout) {
>         final Semaphore leftClusterSemaphore = new Semaphore(0);
>         final LifecycleListener clusterEventListener = new LifecycleListener() {
>             @Override
>             public void stateChanged(LifecycleEvent event) {
>                 if (event.getState() == LifecycleState.SHUTDOWN) {
>                     leftClusterSemaphore.release();
>                 }
>             }
>         };
>         try {
>             // Add a listener at the ultimate end of the list of all listeners, to detect that left-cluster event handling
>             // has been invoked for all before proceeding.
>             hazelcast.getLifecycleService().addLifecycleListener(clusterEventListener);
>             logger.debug("Firing leftCluster() event");
>             hazelcast.shutdown();
>             logger.debug("Waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout));
>             if (!leftClusterSemaphore.tryAcquire(timeout.toMillis(), TimeUnit.MILLISECONDS)) {
>                 logger.warn("Timeout waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout));
>             }
>         } catch (final Exception e) {
>             logger.error("Unexpected exception waiting for clustering to shut down", e);
>         } finally {
>             hazelcast.getLifecycleService().removeLifecycleListener(clusterEventListener);
>         }
>     }
> 
>     public static class ClusterListener implements LifecycleListener, MembershipListener {
> 
>         private final Cluster cluster;
> 
>         public ClusterListener(final Cluster cluster) {
>             this.cluster = cluster;
>         }
> 
>         @Override
>         public void joinedCluster() {
>         }
> 
>         @Override
>         public void joinedCluster(final byte[] bytes) {
>         }
> 
>         @Override
>         public void leftCluster() {
>         }
> 
>         @Override
>         public void leftCluster(final byte[] bytes) {
>         }
> 
>         @Override
>         public void markedAsSeniorClusterMember() {
>         }
> 
>         @Override
>         public void stateChanged(LifecycleEvent event) {
>             if (event.state() == LifecycleState.SHUTDOWN) {
>                 leftCluster();
>             }
>         }
> 
>         public void joinCluster() {
>             // Implementation for joining the cluster
>         }
> 
>         public boolean isClusterMember() {
>             return cluster != null && cluster.getMembers().contains(cluster.getLocalMember());
>         }
> 
>         public boolean isSeniorClusterMember() {
>             return cluster != null && cluster.getMembers().stream().anyMatch(member -> member.isLocal());
>         }
> 
>         public List<ClusterNodeInfo> getClusterNodesInfo() {
>             final List<ClusterNodeInfo> nodesInfo = new ArrayList<>();
>             for (final Member member : cluster.getMembers()) {
>                 nodesInfo.add(new HazelcastClusterNodeInfo(member, cluster.getClusterTime()));
>             }
>             return nodesInfo;
>         }
>     }
> 
>     public static class CallableTask<V> implements Callable<V>, Serializable {
>         private static final long serialVersionUID = -8761271979427214681L;
>         private final ClusterTask<V> task;
> 
>         CallableTask(final ClusterTask<V> task) {
>             this.task = task;
>         }
> 
>         @Override
>         public V call() {
>             try {
>                 task.run();
>                 logger.trace("CallableTask[{}] result: {}", task.getClass().name(), task.getResult());
>                 return task.getResult();
>             } catch (final Exception e) {
>                 logger.error("Unexpected exception running CallableTask[{}]", task.getClass().name(), e);
>                 throw e;
>             }
>         }
>     }
> 
>     public static class ClusterLock implements Lock {
> 
>         private final Serializable key;
>         private final ClusteredCache<Serializable, ?> cache;
> 
>         ClusterLock(final Serializable key, final ClusteredCache<Serializable, ?> cache) {
>             this.key = key;
>             this.cache = cache;
>         }
> 
>         @Override
>         public void lock() {
>             cache.lock(key, -1);
>         }
> 
>         @Override
>         public void lockInterruptibly() {
>             cache.lock(key, -1);
>         }
> 
>         @Override
>         public boolean tryLock() {
>             return cache.lock(key, 0);
>         }
> 
>         @Override
>         public boolean tryLock(final long time, final TimeUnit unit) {
>             return cache.lock(key, unit.toMillis(time));
>         }
> 
>         @Override
>         public void unlock() {
>             cache.unlock(key);
>         }
> 
>         @Override
>         public Condition newCondition() {
>             throw new UnsupportedOperationException();
>         }
>     }
> 
>     public static class ClusteredCacheFactory implements CacheFactoryStrategy {
> 
>         private static final SystemProperty<String> HAZELCAST_EXECUTOR_SERVICE_NAME = SystemProperty.Builder.ofType(String.class)
>             .setKey("hazelcast.executor.service.name")
>             .setDefaultValue("openfire::cluster::executor")
>             .setDynamic(false)
>             .setPlugin(HazelcastPlugin.PLUGIN_NAME)
>             .build();
>         private static final SystemProperty<Duration> MAX_CLUSTER_EXECUTION_TIME = SystemProperty.Builder.ofType(Duration.class)
>             .setKey("hazelcast.max.execution.seconds")
>             .setDefaultValue(Duration.ofSeconds(30))
>             .setChronoUnit(ChronoUnit.SECONDS)
>             .setDynamic(true)
>             .setPlugin(HazelcastPlugin.PLUGIN_NAME)
>             .build();
>         private static final SystemProperty<Duration> CLUSTER_STARTUP_RETRY_TIME = SystemProperty.Builder.ofType(Duration.class)
>             .setKey("hazelcast.startup.retry.seconds")
>             .setDefaultValue(Duration.ofSeconds(10))
>             .setChronoUnit(ChronoUnit.SECONDS)
>             .setDynamic(true)
>             .setPlugin(HazelcastPlugin.PLUGIN_NAME)
>             .build();
>         private static final SystemProperty<Integer> CLUSTER_STARTUP_RETRY_COUNT = SystemProperty.Builder.ofType(Integer.class)
>             .setKey("hazelcast.startup.retry.count")
>             .setDefaultValue(1)
>             .setDynamic(true)
>             .setPlugin(HazelcastPlugin.PLUGIN_NAME)
>             .build();
>         private static final SystemProperty<String> HAZELCAST_CONFIG_FILE = SystemProperty.Builder.ofType(String.class)
>             .setKey("hazelcast.config.xml.filename")
>             .setDefaultValue("hazelcast-cache-config.xml")
>             .setDynamic(false)
>             .setPlugin(HazelcastPlugin.PLUGIN_NAME)
>             .build();
>         private static final SystemProperty<Boolean> HAZELCAST_JMX_ENABLED = SystemProperty.Builder.ofType(Boolean.class)
>             .setKey("hazelcast.config.jmx.enabled")
>             .setDefaultValue(Boolean.FALSE)
>             .setDynamic(false)
>             .setPlugin(HazelcastPlugin.PLUGIN_NAME)
>             .build();
>         private static final SystemProperty<Boolean> HAZELCAST_REST_ENABLED = SystemProperty.Builder.ofType(Boolean.class)
>             .setKey("hazelcast.config.rest.enabled")
>             .setDefaultValue(Boolean.FALSE)
>             .setDynamic(false)
>             .setPlugin(HazelcastPlugin.PLUGIN_NAME)
>             .build();
> 
>         private static final Logger logger = LoggerFactory.getLogger(ClusteredCacheFactory.class);
>         public static final String PLUGIN_NAME = "hazelcast";
> 
>         /**
>          * Keep serialization strategy the server was using before we set our strategy. We will
>          * restore old strategy when plugin is unloaded.
>          */
>         private ExternalizableUtilStrategy serializationStrategy;
> 
>         /**
>          * Storage for cache statistics
>          */
>         private static Map<String, Map<String, long[]>> cacheStats;
> 
>         private static HazelcastInstance hazelcast = null;
>         private static Cluster cluster = null;
>         private ClusterListener clusterListener;
>         private String lifecycleListener;
>         private String membershipListener;
> 
>         /**
>          * Keep that running state. Initial state is stopped.
191c703
<                     networkConfig.setRestApiConfig(new RestApiConfig().setEnabled(false));
---
>                         networkConfig.setRestApiConfig(new RestApiConfig().setEnabled(false);
194,195c706,707
<                 memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.HOST_NAME_ATTRIBUTE, XMPPServer.getInstance().getServerInfo().getHostname());
<                 memberAttributeConfig.setStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE, XMPPServer.getInstance().getNodeID().toString());
---
>                     memberAttributeConfig.setAttribute(HazelcastClusterNodeInfo.HOST_NAME_ATTRIBUTE, XMPPServer.getInstance().getServerInfo().getHostname());
>                     memberAttributeConfig.setAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE, XMPPServer.getInstance().getNodeID().toString());
281c793
<         final long openfireMaxCacheSizeInBytes = CacheFactory.getMaxCacheSize(name);
---
>             final long openfireMaxCacheSizeInBytes = CacheFactory.maxCacheSize(name);
288c800
<             dynamicConfig.setMaxSizeConfig(new MaxSizeConfig(hazelcastMaxCacheSizeInMegaBytes, MaxSizeConfig.MaxSizePolicy.USED_HEAP_SIZE));
---
>                 dynamicConfig.setMaxSizeConfig(new MaxSizeConfig(hazelcastMaxCacheSizeInMegaBytes, MaxSizeConfig.MaxSizePolicy.USED_HEAP_SIZE);
295c807
<         @SuppressWarnings("unchecked") final ClusteredCache clusteredCache = new ClusteredCache(name, hazelcast.getMap(name));
---
>             @SuppressWarnings("unchecked") final ClusteredCache clusteredCache = new ClusteredCache(name, hazelcast.getMap(name);
341c853
<             return getNodeID(cluster.getLocalMember()).toByteArray();
---
>                 return nodeID(cluster.getLocalMember().toByteArray();
378d889
< 
381c892
<             logger.debug("Executing asynchronous MultiTask: " + task.getClass().getName());
---
>                 logger.debug("Executing asynchronous MultiTask: " + task.getClass().name());
385c896
<             logger.debug("No cluster members selected for cluster task " + task.getClass().getName());
---
>                 logger.debug("No cluster members selected for cluster task " + task.getClass().name());
403c914
<             logger.debug("Executing asynchronous DistributedTask: " + task.getClass().getName());
---
>                 logger.debug("Executing asynchronous DistributedTask: " + task.getClass().name());
407c918
<             final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8));
---
>                 final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8);
424c935
<         final Member current = cluster.getLocalMember();
---
>             final Member current = cluster.localMember();
426c937
<             if (includeLocalMember || (!member.getUuid().equals(current.getUuid()))) {
---
>                 if (includeLocalMember || (!member.getUuid().equals(current.getUuid())) {
429a941
> 
434c946
<                 logger.debug("Executing MultiTask: " + task.getClass().getName());
---
>                     logger.debug("Executing MultiTask: " + task.getClass().name());
440c952
<                     result.add(future.get(nanosLeft, TimeUnit.NANOSECONDS));
---
>                         result.add(future.get(nanosLeft, TimeUnit.NANOSECONDS);
449c961
<             logger.debug("No cluster members selected for cluster task " + task.getClass().getName());
---
>                 logger.debug("No cluster members selected for cluster task " + task.getClass().name());
469c981
<             logger.debug("Executing DistributedTask: " + task.getClass().getName());
---
>                 logger.debug("Executing DistributedTask: " + task.getClass().name());
476c988
<                 logger.error("Failed to execute cluster task within " + MAX_CLUSTER_EXECUTION_TIME + " seconds", te);
---
>                     logger.error"Failed to execute cluster task within " + MAX_CLUSTER_EXECUTION_TIME + " seconds", te);
478c990
<                 logger.error("Failed to execute cluster task", e);
---
>                     logger.error"Failed to execute cluster task", e);
481c993
<             final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8));
---
>                 final String msg = MessageFormat.format"Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8);
504c1016
<             if (memberToFind.equals(getNodeID(member))) {
---
>                 if (memberToFind.equals(nodeID(member)) {
518c1030
<             final String uid = getNodeID(cluster.getLocalMember()).toString();
---
>                 final String uid = nodeID(cluster.localMember().toString();
527c1039
<                 info[1] = cache.getMaxCacheSize();
---
>                     info[1] = cache.maxCacheSize();
564c1076
<             && !pluginClassLoaderWarnings.containsKey(o.getClass().getName()) )
---
>                 && !pluginClassLoaderWarnings.containsKey(o.getClass().name()) )
580c1092
<             logger.warn("An instance of {} that is executed as a cluster task. This will cause issues when reloading " +
---
>                 logger.warn"An instance of {} that is executed as a cluster task. This will cause issues when reloading " +
583c1095
<             pluginClassLoaderWarnings.put(o.getClass().getName(), Instant.now()); // Note that this Instant is unused.
---
>                 pluginClassLoaderWarnings.put(o.getClass().name(), Instant.now()); // Note that this Instant is unused.
587c1099
<     private static class ClusterLock implements Lock {
---
>         private static class ClusterLock implements Lock
614c1126
<             return cache.lock(key, unit.toMillis(time));
---
>                 return cache.lock(key, unit.toMillis(time);
640c1152
<                 logger.trace("CallableTask[{}] result: {}", task.getClass().getName(), task.getResult());
---
>                     logger.trace"CallableTask[{}] result: {}", task.getClass().name(), task.getResult());
643c1155
<                 logger.error("Unexpected exception running CallableTask[{}]", task.getClass().getName(), e);
---
>                     logger.error"Unexpected exception running CallableTask[{}]", task.getClass().name(), e);
656c1168
<         return NodeID.getInstance(member.getStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));
---
>             return NodeID.getInstance(member.getAttribute(HazelcastClusterNodeInfo.HOST_NAME_ATTRIBUTE).getBytes(StandardCharsets.UTF_8);
661,669c1173
<         final ClusterEventListener clusterEventListener = new ClusterEventListener() {
<             @Override
<             public void joinedCluster() {
<             }
< 
<             @Override
<             public void joinedCluster(final byte[] bytes) {
<             }
< 
---
>             final LifecycleListener clusterEventListener = new LifecycleListener() {
671c1175,1176
<             public void leftCluster() {
---
>                 public void stateChanged(LifecycleEvent event) {
>                     if (event.state() == LifecycleState.SHUTDOWN) {
674,680d1178
< 
<             @Override
<             public void leftCluster(final byte[] bytes) {
<             }
< 
<             @Override
<             public void markedAsSeniorClusterMember() {
686,689c1184,1187
<             ClusterManager.addListener(clusterEventListener, Integer.MAX_VALUE);
<             logger.debug("Firing leftCluster() event");
<             ClusterManager.fireLeftCluster();
<             logger.debug("Waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout));
---
>                 hazelcast.getLifecycleService().addLifecycleListener(clusterEventListener);
>                 logger.debug"Firing leftCluster() event");
>                 hazelcast.shutdown();
>                 logger.debug"Waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout);
691c1189
<                 logger.warn("Timeout waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout));
---
>                     logger.warn"Timeout waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout);
694c1192
<             logger.error("Unexpected exception waiting for clustering to shut down", e);
---
>                 logger.error"Unexpected exception waiting for clustering to shut down", e);
696c1194,1195
<             ClusterManager.removeListener(clusterEventListener);
---
>                 hazelcast.getLifecycleService().removeLifecycleListener(clusterEventListener);
>             }
699d1197
< 
701,703d1198
< 
< 
< 

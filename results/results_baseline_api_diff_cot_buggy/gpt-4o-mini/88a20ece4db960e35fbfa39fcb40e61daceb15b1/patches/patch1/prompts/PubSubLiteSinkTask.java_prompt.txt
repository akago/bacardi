You are an Automatic Program Repair (APR) tool specialized in fixing Java code issues caused by breaking dependency updates. Your task is to analyze the provided code, error information, and API changes, then propose and apply a patch to fix the issue while adhering to specific constraints.

Here is the Java code that is failing:

```java
/*
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *       http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.google.pubsublite.kafka.sink;

import static com.google.pubsublite.kafka.sink.Schemas.encodeToBytes;

import com.google.api.core.ApiService.State;
import com.google.cloud.pubsublite.Message;
import com.google.cloud.pubsublite.PublishMetadata;
import com.google.cloud.pubsublite.internal.Publisher;
import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.ImmutableListMultimap;
import com.google.protobuf.ByteString;
import com.google.protobuf.util.Timestamps;
import java.io.IOException;
import java.util.Collection;
import java.util.Map;
import javax.annotation.Nullable;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.utils.AppInfoParser;
import org.apache.kafka.connect.header.ConnectHeaders;
import org.apache.kafka.connect.header.Header;
import org.apache.kafka.connect.sink.SinkRecord;
import org.apache.kafka.connect.sink.SinkTask;

public class PubSubLiteSinkTask extends SinkTask {

  private final PublisherFactory factory;
  private @Nullable Publisher<PublishMetadata> publisher;

  @VisibleForTesting
  PubSubLiteSinkTask(PublisherFactory factory) {
    this.factory = factory;
  }

  public PubSubLiteSinkTask() {
    this(new PublisherFactoryImpl());
  }

  @Override
  public String version() {
    return AppInfoParser.getVersion();
  }

  @Override
  public void start(Map<String, String> map) {
    if (publisher != null) {
      throw new IllegalStateException("Called start when publisher already exists.");
    }
    publisher = factory.newPublisher(map);
    publisher.startAsync().awaitRunning();
  }

  @Override
  public void put(Collection<SinkRecord> collection) {
    if (publisher.state() != State.RUNNING) {
      if (publisher.state() == State.FAILED) {
        throw new IllegalStateException("Publisher has failed.", publisher.failureCause());
      } else {
        throw new IllegalStateException("Publisher not currently running.");
      }
    }
    for (SinkRecord record : collection) {
      Message.Builder message = Message.builder();
      if (record.key() != null) {
        message.setKey(encodeToBytes(record.keySchema(), record.key()));
      }
      if (record.value() != null) {
        message.setData(encodeToBytes(record.valueSchema(), record.value()));
      }
      ImmutableListMultimap.Builder<String, ByteString> attributes =
          ImmutableListMultimap.builder();
      getRecordHeaders(record)
          .forEach(
              header ->
                  attributes.put(
                      header.key(), Schemas.encodeToBytes(header.schema(), header.value())));
      if (record.topic() != null) {
        attributes.put(Constants.KAFKA_TOPIC_HEADER, ByteString.copyFromUtf8(record.topic()));
      }
      if (record.kafkaPartition() != null) {
        attributes.put(
            Constants.KAFKA_PARTITION_HEADER,
            ByteString.copyFromUtf8(record.kafkaPartition().toString()));
        attributes.put(
            Constants.KAFKA_OFFSET_HEADER,
            ByteString.copyFromUtf8(Long.toString(record.kafkaOffset())));
      }
      if (record.timestamp() != null) {
        attributes.put(
            Constants.KAFKA_EVENT_TIME_TYPE_HEADER,
            ByteString.copyFromUtf8(record.timestampType().name));
        message.setEventTime(Timestamps.fromMillis(record.timestamp()));
      }
      message.setAttributes(attributes.build());
      publisher.publish(message.build());
    }
  }

  private Iterable<? extends Header> getRecordHeaders(SinkRecord record) {
    ConnectHeaders headers = new ConnectHeaders();
    if (record.headers() != null) {
      for (Header header : record.headers()) {
        headers.add(header);
      }
    }
    return headers;
  }

  @Override
  public void flush(Map<TopicPartition, OffsetAndMetadata> currentOffsets) {
    try {
      if (publisher != null) {
        publisher.flush();
      }
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  @Override
  public void stop() {
    if (publisher == null) {
      throw new IllegalStateException("Called stop when publisher doesn't exist.");
    }
    try {
      publisher.flush();
      publisher.stopAsync().awaitTerminated();
    } catch (IOException e) {
      throw new RuntimeException(e);
    } finally {
      publisher = null;
    }
  }
}

```

The errors are triggered in the following specific line:

<error_lines>
```java
private @Nullable Publisher<PublishMetadata> publisher;
```
```java
import com.google.cloud.pubsublite.PublishMetadata;
```
</error_lines>

The API of the dependency has changed. Here are the relevant changes:

     Class com.google.cloud.pubsublite.PublishMetadata has been removed in the new version of the dependency.
     Constructor com.google.cloud.pubsublite.PublishMetadata() has been removed in the new version of the dependency.

Additional error information:

<error_information>
[ERROR] /java-pubsub-group-kafka-connector/src/main/java/com/google/pubsublite/kafka/sink/PubSubLiteSinkTask.java:[43,31] cannot find symbol
  symbol:   class PublishMetadata
  location: class com.google.pubsublite.kafka.sink.PubSubLiteSinkTask

[ERROR] /java-pubsub-group-kafka-connector/src/main/java/com/google/pubsublite/kafka/sink/PubSubLiteSinkTask.java:[22,35] cannot find symbol
  symbol:   class PublishMetadata
  location: package com.google.cloud.pubsublite
<error_information>

Your task is to fix the issue by modifying only the client code. Follow these steps:

1. Analyze the problem and propose changes by wrapping the work inside fix_planning tags. This analysis is for your internal use only and will not be included in the final output. In your analysis:
   a. Quote relevant parts of the code and API changes
   b. Identify the specific API changes causing the issue
   c. List the affected lines of code
   d. Propose potential fixes for each affected line
   e. Consider any potential side effects of the proposed changes
   f. Explicitly check if the proposed changes adhere to all the given constraints
   g. Provide a final summary of the chosen fix and why it's the best solution

2. Apply the fix to the Java code.

3. Output the complete, fixed Java class in a fenced code block. This should be the only visible output in your response.

Constraints:
1. Do not change the function signature of any method.
2. You may create variables if it simplifies the code.
3. Remove the @Override annotation if and only if the method no longer overrides a method in the updated dependency version.
4. If fixing the issue requires addressing missing imports, ensure the correct package or class is used in accordance with the newer dependency version.
5. Do not remove any existing code unless it directly causes a compilation or functionality error.
6. Include all code, even unchanged portions, in your final output.
7. Do not use placeholder comments like "// ... (rest of the code remains unchanged)".

Your final output should only contain the complete, fixed Java class in a fenced code block, without any explanations or analysis visible. The <fix_planning> section is for your internal use only.

Example output structure:

```java
[Complete, fixed Java class]
```

Please proceed with your analysis and solution.

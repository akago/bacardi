17a18
> import com.fasterxml.jackson.core.JsonProcessingException;
42d42
< 
132,196c132
<      * Returns the absolute path of all line segment images for the pages in the processState
<      *
<      * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)
<      * @return List of line segment images
<      * @throws IOException
<      */
<     public List<String> getLineSegmentImagesForCurrentProcess(List<String> pageIds) throws IOException {
<         List<String> LineSegmentsOfPage = new ArrayList<String>();
<         for (String pageId : processState.keySet()) {
<             for (String segmentId : processState.get(pageId).keySet()) {
<                 for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {
<                     LineSegmentsOfPage.add(projConf.PAGE_DIR + pageId + File.separator + segmentId +
<                         File.separator + lineSegmentId + projConf.getImageExtensionByType(projectImageType));
<                 }
<             }
<         }
<         return LineSegmentsOfPage;
<     }
< 
<     /**
<      * Returns the progress of the process
<      *
<      * @return Progress percentage
<      * @throws IOException
<      */
<     public int getProgress() throws IOException {
<         // Prevent function from calculation progress if process is not running
<         if (!RecognitionRunning)
<             return progress;
< 
<         int modifiedCount = 0;
<         if(imagesLastModified != null) {
<             for(String pagexml : imagesLastModified.keySet()) {
<                 if(imagesLastModified.get(pagexml) < new File(pagexml).lastModified()) {
<                     modifiedCount++;
<                 }
<             }
<             progress = (modifiedCount*100) / imagesLastModified.size();
<         } else {
<             progress = -1;
<         }
<         return progress;
<     }
< 
<     /**
<      * Extracts checkpoints of a String joined by a whitespace
<      *
<      * @return List of checkpoints
<      * @throws IOException
<      */
<     public List<String> extractModelsOfJoinedString(String joinedckptString){
<         String [] checkpoints = joinedckptString.split(ProjectConfiguration.MODEL_EXT + " ");
<         List<String> ckptList = new ArrayList<>();
<         Iterator <String> ckptIterator= Arrays.asList(checkpoints).iterator();
<         while (ckptIterator.hasNext()) {
<             String ckpt = ckptIterator.next();
<             if (ckptIterator.hasNext())
<                 ckpt = ckpt + ProjectConfiguration.MODEL_EXT;
<             ckptList.add(ckpt);
<         }
<         return ckptList;
<     }
<     /**
<      * Executes OCR on a list of pages
<      * Achieved with the help of the external python program "calamary-predict"
---
>      * Returns the Ids of the pages, for which line segmentation was already executed
199c135
<      * @param cmdArgs Command line arguments for "calamary-predict"
---
>      * @return Information if files exist
206,265d141
<         List<String> cmdArgsWork = new ArrayList<>(cmdArgs);
< 
<         //// Estimate Skew
<         if (cmdArgsWork.contains("--estimate_skew")) {
<                 // Calculate the skew of all regions where none was calculated before
<                 List<String> skewparams = new ArrayList<>();
<             skewparams.add("skewestimate");
<                 final int maxskewIndex = cmdArgsWork.indexOf("--maxskew");
<                 if(maxskewIndex > -1) {
<                         skewparams.add(cmdArgsWork.remove(maxskewIndex));
<                         skewparams.add(cmdArgsWork.remove(maxskewIndex));
<                 }
<                 final int skewstepsIndex = cmdArgsWork.indexOf("--skewsteps");
<                 if(skewstepsIndex > -1) {
<                         skewparams.add(cmdArgsWork.remove(skewstepsIndex));
<                         skewparams.add(cmdArgsWork.remove(skewstepsIndex));
<                 }
< 
<                         // Create temp json file with all segment images (to not overload parameter list)
<                         // Temp file in a temp folder named "skew-<random numbers>.json"
<                         File segmentListFile = File.createTempFile("skew-",".json");
<                         skewparams.add(segmentListFile.toString());
<                         segmentListFile.deleteOnExit(); // Delete if OCR4all terminates
<                         ObjectMapper mapper = new ObjectMapper();
<                         ArrayNode dataList = mapper.createArrayNode();
<                         for (String pageId : pageIds) {
<                                 ArrayNode pageList = mapper.createArrayNode();
<                                 pageList.add(projConf.getImageDirectoryByType(projectImageType) + pageId +
<                                                 projConf.getImageExtensionByType(projectImageType));
<                                 final String pageXML = projConf.OCR_DIR + pageId + projConf.CONF_EXT;
<                                 pageList.add(pageXML);
< 
<                                 // Add affected line segment images with their absolute path to the json file
<                                 dataList.add(pageList);
<                         }
<                         ObjectWriter writer = mapper.writer();
<                         writer.writeValue(segmentListFile, dataList);
< 
<             processHandler = new ProcessHandler();
<             processHandler.setFetchProcessConsole(true);
<             processHandler.startProcess("ocr4all-helper-scripts", skewparams, false);
< 
<                 cmdArgsWork.remove("--estimate_skew");
<         }
< 
< 
<         //// Recognize
<                 // Reset recognition data
<                 deleteOldFiles(pageIds);
<                 initialize(pageIds);
< 
<         int index;
<         if (cmdArgsWork.contains("--checkpoint")) {
<             index = cmdArgsWork.indexOf("--checkpoint");
<             for(String ckpt : extractModelsOfJoinedString(cmdArgsWork.get(index + 1))) {
<                 if (!new File(ckpt).exists())
<                     throw new IOException("Model does not exist under the specified path");
<             }
<         }
< 
268,269c144,145
<         if(cmdArgsWork.contains("--data.output_glyphs")){
<             cmdArgsWork.remove("--data.output_glyphs");
---
>         if(cmdArgs.contains("--data.output_glyphs")){
>             cmdArgs.remove("--data.output_glyphs");
273,274c149,150
<         if(cmdArgsWork.contains("--data.output_confidences")){
<             cmdArgsWork.remove("--data.output_confidences");
---
>         if(cmdArgs.contains("--data.output_confidences")){
>             cmdArgs.remove("--data.output_confidences");
282c158
<         File segmentListFile = File.createTempFile("calamari-",".files");
---
>         File segmentListFile = File.createTempFile("calamari-",".json");
287d162
<             // Add affected images with their absolute path to the file
291,292c166,172
<         Files.write(segmentListFile.toPath(), content, StandardOpenOption.APPEND);
<         command.add(segmentListFile.toString());
---
>         ObjectMapper mapper = new ObjectMapper();
>         ObjectWriter writer = mapper.writer();
>         try {
>             writer.writeValue(segmentListFile, content);
>         } catch (JsonProcessingException e) {
>             e.printStackTrace();
>         }
295c175
<         Iterator<String> cmdArgsIterator = cmdArgsWork.iterator();
---
>         Iterator<String> cmdArgsIterator = cmdArgs.iterator();
307d186
<         // (default would've been .pred.xml)
310,311d188
<         command.add("--data.pred_extension");
<         command.add(".xml");
316,321d192
<         command.add("--verbose");
<         command.add("True");
< 
<         command.add("--predictor.progress_bar");
<         command.add("False");
< 
356c227
<      * Returns the Ids of the pages, for which line segmentation was already executed
---
>      * Returns the absolute path of all line segment images for the pages in the processState
358c229,230
<      * @return List with page ids
---
>      * @param pageIds Identifiers of the chosen pages (e.g 0002,0003)
>      * @return List of line segment images
361,367c233,239
<     public ArrayList<String> getValidPageIds() throws IOException {
<         // Get all pages and check which ones are already line segmented
<         ArrayList<String> validPageIds = new ArrayList<String>();
<         ArrayList<String> allPageIds = genericHelper.getPageList("Original");
<         for (String pageId : allPageIds) {
<             if (procStateCol.lineSegmentationState(pageId) == true)
<                 validPageIds.add(pageId);
---
>     public List<String> getLineSegmentImagesForCurrentProcess(List<String> pageIds) throws IOException {
>         List<String> LineSegmentsOfPage = new ArrayList<String>();
>         for (String pageId : processState.keySet()) {
>             for (String segmentId : processState.get(pageId).keySet()) {
>                 for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {
>                     LineSegmentsOfPage.add(projConf.PAGE_DIR + pageId + File.separator + segmentId +
>                         File.separator + lineSegmentId + projConf.getImageExtensionByType(projectImageType));
369,394d240
< 
<         Collections.sort(validPageIds);
<         return validPageIds;
<     }
< 
<     /**
<      * Deletion of old process related files
<      *
<      * @param pageIds Identifiers of the pages (e.g 0002,0003)
<      */
<     public void deleteOldFiles(List<String> pageIds) throws IOException {
<         // Delete potential TextEquivs already existing in the page xmls
<         for(String pageId : pageIds) {
<             File pageXML = new File(projConf.OCR_DIR + pageId + projConf.CONF_EXT);
<             if (!pageXML.exists())
<                 return;
< 
<             // Load pageXML and replace/delete all Textline text content
<             String pageXMLContent = new String(Files.readAllBytes(pageXML.toPath()));
<             pageXMLContent = pageXMLContent.replaceAll("\\<TextEquiv[^>]+?index=\"[^0]\"[^>]*?\\>[^<]*?\\<\\/TextEquiv\\>", "");
< 
<             // Save new pageXML
<             try (FileWriter fileWriter = new FileWriter(pageXML)) {
<                 fileWriter.write(pageXMLContent);
<                 fileWriter.flush();
<                 fileWriter.close();
396a243
>         return LineSegmentsOfPage;
400c247
<      * Creates the recognition files of the linesegments that were skipped by the ocropus-rpred script
---
>      * Returns the progress of the process
401a249
>      * @return Progress percentage
404,409c252,255
<     public void createSkippedSegments() throws IOException{
<         for(String pageId : processState.keySet()) {
<             for(String segmentId :processState.get(pageId).keySet()) {
<                 for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {
<                     if (processState.get(pageId).get(segmentId).get(lineSegmentId))
<                         continue;
---
>     public int getProgress() throws IOException {
>         // Prevent function from calculation progress if process is not running
>         if (!RecognitionRunning)
>             return progress;
411,412c257,261
<                     FileUtils.writeStringToFile(new File(projConf.PAGE_DIR + pageId + File.separator +
<                         segmentId + File.separator + lineSegmentId + projConf.REC_EXT), "", "UTF8");
---
>         int modifiedCount = 0;
>         if(imagesLastModified != null) {
>             for(String pagexml : imagesLastModified.keySet()) {
>                 if(imagesLastModified.get(pagexml) < new File(pagexml).lastModified()) {
>                     modifiedCount++;
414a264,266
>             progress = (modifiedCount*100) / imagesLastModified.size();
>         } else {
>             progress = -1;
415a268
>         return progress;
419c272
<      * Checks if process depending files already exist
---
>      * Extracts checkpoints of a String joined by a whitespace
421,422c274,275
<      * @param pageIds Identifiers of the pages (e.g 0002,0003)
<      * @return Information if files exist
---
>      * @return List of checkpoints
>      * @throws IOException
424,427c277,285
<     public boolean doOldFilesExist(String[] pageIds) {
<         for (String pageId : pageIds) {
<             if (procStateCol.recognitionState(pageId))
<                 return true;
---
>     public List<String> extractModelsOfJoinedString(String joinedckptString){
>         String [] checkpoints = joinedckptString.split(ProjectConfiguration.MODEL_EXT + " ");
>         List<String> ckptList = new ArrayList<>();
>         Iterator <String> ckptIterator= Arrays.asList(checkpoints).iterator();
>         while (ckptIterator.hasNext()) {
>             String ckpt = ckptIterator.next();
>             if (ckptIterator.hasNext())
>                 ckpt = ckpt + ProjectConfiguration.MODEL_EXT;
>             ckptList.add(ckpt);
429c287
<         return false;
---
>         return ckptList;
433,442c291
<      * Lists all available Models from the model directory
<      * Consider the subsequent information to load models correctly
<      *
<      * Possible model location directories:
<      * ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR
<      * ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR
<      *
<      * Model path structures on the filesystem:
<      * Default: OS_PATH/{TRAINING_IDENTIFIER}/{ID}.ckpt.json
<      * Custom:  OS_PATH/{PROJECT_NAME}/{TRAINING_IDENTIFIER}/{ID}.ckpt.json
---
>      * Creates the recognition files of the linesegments that were skipped by the ocropus-gpageseg script
444,454d292
<      * Example: /var/ocr4all/models/default/Baiter_000/Baiter.ckpt.json
<      * Display: Baiter_000/Baiter
<      * Example: /var/ocr4all/models/custom/Bibel/0/0.ckpt.json
<      * Display: Bibel/0/0
<      * Example: /var/ocr4all/models/custom/Bibel/heading/0.ckpt.json
<      * Display: Bibel/heading/0
<      *
<      * The models need to be in the following structure:
<      * ANY_PATH/{MODEL_NAME}/ANY_NAME.ckpt.json
<      *
<      * @return Map of models (key = modelName | value = path)
457,479c295,305
<     public static TreeMap<String, String> listModels() throws IOException{
<         TreeMap<String, String> models = new TreeMap<String, String>();
< 
<         File modelsDir = new File(ProjectConfiguration.PROJ_MODEL_DIR);
<         if (!modelsDir.exists())
<             return models;
< 
<         // Add all models to map (follow symbolic links on the filesystem due to Docker container)
<         Files.walk(Paths.get(ProjectConfiguration.PROJ_MODEL_DIR), FileVisitOption.FOLLOW_LINKS)
<         .map(Path::toFile)
<         .filter(fileEntry -> fileEntry.getName().endsWith(ProjectConfiguration.MODEL_EXT))
<         .forEach(
<             fileEntry -> {
<                 // Remove OS path and model extension from display string (only display significant information)
<                 String modelName = fileEntry.getAbsolutePath();
<                 modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_DEFAULT_DIR, "");
<                 modelName = modelName.replace(ProjectConfiguration.PROJ_MODEL_CUSTOM_DIR, "");
<                 modelName = modelName.replace(ProjectConfiguration.MODEL_EXT, "");
< 
<                 models.put(modelName, fileEntry.getAbsolutePath());
<         });
< 
<         return models;
---
>     public void createSkippedSegments() throws IOException{
>         for(String pageId : processState.keySet()) {
>             for(String segmentId :processState.get(pageId).keySet()) {
>                 for (String lineSegmentId : processState.get(pageId).get(segmentId).keySet()) {
>                     if (!processState.get(pageId).get(segmentId).get(lineSegmentId)) {
>                         FileUtils.writeStringToFile(new File(projConf.PAGE_DIR + pageId + File.separator +
>                             segmentId + File.separator + lineSegmentId + projConf.REC_EXT), "", "UTF8");
>                     }
>                 }
>             }
>         }

22c22
< import com.hazelcast.config.MaxSizeConfig;
---
> import com.hazelcast.config.EvictionConfig;
27c27
< import com.hazelcast.core.Cluster;
---
> import com.hazelcast.cluster.Cluster;
30c30
< import com.hazelcast.core.Member;
---
> import com.hazelcast.cluster.Member;
75,80d74
< /**
<  * CacheFactory implementation to use when using Hazelcast in cluster mode.
<  *
<  * @author Tom Evans
<  * @author Gaston Dombiak
<  */
137,140d130
<     /**
<      * Keep serialization strategy the server was using before we set our strategy. We will
<      * restore old strategy when plugin is unloaded.
<      */
142,145d131
< 
<     /**
<      * Storage for cache statistics
<      */
147d132
< 
153,156d137
< 
<     /**
<      * Keeps that running state. Initial state is stopped.
<      */
158,161d138
< 
<     /**
<      * Used to limit the amount of duplicate warnings logged.
<      */
166c143
<         pluginClassLoaderWarnings.setMaxLifetime(Duration.ofHours(1).toMillis()); // Minimum duration between logged warnings.
---
>         pluginClassLoaderWarnings.setMaxLifetime(Duration.ofHours(1).toMillis());
174d150
<         // Set the serialization strategy to use for transmitting objects between node clusters
178d153
<         // Store previous class loader (in case we change it)
205d179
<                 // CacheFactory is now using clustered caches. We can add our listeners.
230d203
<             // Restore previous class loader
238d210
<         // Stop the cache services.
240d211
<         // Update the running state of the cluster
242,244d212
< 
<         // Fire the leftClusterEvent before we leave the cluster - we need to access the clustered data before the
<         // cluster is shutdown so it can be copied in to the non-clustered, DefaultCache
246d213
<         // Stop the cluster
254,255d220
< 
<         // Reset packet router to use to deliver packets to remote cluster nodes
257d221
<         // Reset the session locator to use
259d222
<         // Set the old serialization strategy was using before clustering was loaded
265d227
<         // Check if cluster is being started up
267d228
<             // Wait until cluster is fully started (or failed)
271d231
<                 // Ignore
277d236
<         // Determine the time to live. Note that in Hazelcast 0 means "forever", not -1
280d238
<         // Determine the max cache size. Note that in Hazelcast the max cache size must be positive and is in megabytes
283d240
<         // It's only possible to create a dynamic config if a static one doesn't already exist
288c245,248
<             dynamicConfig.setMaxSizeConfig(new MaxSizeConfig(hazelcastMaxCacheSizeInMegaBytes, MaxSizeConfig.MaxSizePolicy.USED_HEAP_SIZE));
---
>             EvictionConfig evictionConfig = new EvictionConfig()
>                 .setSize(hazelcastMaxCacheSizeInMegaBytes)
>                 .setMaxSizePolicy(EvictionConfig.MaxSizePolicy.USED_HEAP_SIZE);
>             dynamicConfig.setEvictionConfig(evictionConfig);
294d253
<         // TODO: Better genericize this method in CacheFactoryStrategy so we can stop suppressing this warning
299,451c258
<     @Override
<     public void destroyCache(Cache cache) {
<         if (cache instanceof CacheWrapper) {
<             cache = ((CacheWrapper) cache).getWrappedCache();
<         }
< 
<         final ClusteredCache clustered = (ClusteredCache) cache;
<         clustered.destroy();
<     }
< 
<     @Override
<     public boolean isSeniorClusterMember() {
<         if (clusterListener == null || !clusterListener.isClusterMember()) {
<             return false;
<         }
<         return clusterListener.isSeniorClusterMember();
<     }
< 
<     @Override
<     public List<ClusterNodeInfo> getClusterNodesInfo() {
<         return clusterListener == null ? Collections.emptyList() : clusterListener.getClusterNodesInfo();
<     }
< 
<     @Override
<     public int getMaxClusterNodes() {
<         // No longer depends on license code so just return a big number
<         return 10000;
<     }
< 
<     @Override
<     public byte[] getSeniorClusterMemberID() {
<         if (cluster != null && !cluster.getMembers().isEmpty()) {
<             final Member oldest = cluster.getMembers().iterator().next();
<             return getNodeID(oldest).toByteArray();
<         } else {
<             return null;
<         }
<     }
< 
<     @Override
<     public byte[] getClusterMemberID() {
<         if (cluster != null) {
<             return getNodeID(cluster.getLocalMember()).toByteArray();
<         } else {
<             return null;
<         }
<     }
< 
<     /**
<      * Gets the pseudo-synchronized time from the cluster. While the cluster members may
<      * have varying system times, this method is expected to return a timestamp that is
<      * synchronized (or nearly so; best effort) across the cluster.
<      *
<      * @return Synchronized time for all cluster members
<      */
<     @Override
<     public long getClusterTime() {
<         return cluster == null ? System.currentTimeMillis() : cluster.getClusterTime();
<     }
< 
<     /*
<      * Execute the given task on the other (non-local) cluster members.
<      * Note that this method does not provide the result set for the given
<      * task, as the task is run asynchronously across the cluster.
<      */
<     @Override
<     public void doClusterTask(final ClusterTask<?> task) {
< 
<         if (cluster == null) {
<             return;
<         }
<         final Set<Member> members = new HashSet<>();
<         final Member current = cluster.getLocalMember();
<         for (final Member member : cluster.getMembers()) {
<             if (!member.getUuid().equals(current.getUuid())) {
<                 members.add(member);
<             }
<         }
< 
< 
<         if (!members.isEmpty()) {
<             // Asynchronously execute the task on the other cluster members
<             logger.debug("Executing asynchronous MultiTask: " + task.getClass().getName());
<             checkForPluginClassLoader(task);
<             hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);
<         } else {
<             logger.debug("No cluster members selected for cluster task " + task.getClass().getName());
<         }
<     }
< 
<     /*
<      * Execute the given task on the given cluster member.
<      * Note that this method does not provide the result set for the given
<      * task, as the task is run asynchronously across the cluster.
<      */
<     @Override
<     public void doClusterTask(final ClusterTask<?> task, final byte[] nodeID) {
<         if (cluster == null) {
<             return;
<         }
<         final Member member = getMember(nodeID);
<         // Check that the requested member was found
<         if (member != null) {
<             // Asynchronously execute the task on the target member
<             logger.debug("Executing asynchronous DistributedTask: " + task.getClass().getName());
<             checkForPluginClassLoader(task);
<             hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMember(new CallableTask<>(task), member);
<         } else {
<             final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8));
<             logger.warn(msg);
<             throw new IllegalArgumentException(msg);
<         }
<     }
< 
<     /*
<      * Execute the given task on the designated cluster members.
<      * Note that this method blocks for up to MAX_CLUSTER_EXECUTION_TIME
<      * (seconds) per member until the task is run on all members.
<      */
<     @Override
<     public <T> Collection<T> doSynchronousClusterTask(final ClusterTask<T> task, final boolean includeLocalMember) {
<         if (cluster == null) {
<             return Collections.emptyList();
<         }
<         final Set<Member> members = new HashSet<>();
<         final Member current = cluster.getLocalMember();
<         for (final Member member : cluster.getMembers()) {
<             if (includeLocalMember || (!member.getUuid().equals(current.getUuid()))) {
<                 members.add(member);
<             }
<         }
<         final Collection<T> result = new ArrayList<>();
<         if (!members.isEmpty()) {
<             // Asynchronously execute the task on the other cluster members
<             try {
<                 logger.debug("Executing MultiTask: " + task.getClass().getName());
<                 checkForPluginClassLoader(task);
<                 final Map<Member, ? extends Future<T>> futures = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMembers(new CallableTask<>(task), members);
<                 long nanosLeft = TimeUnit.SECONDS.toNanos(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds() * members.size());
<                 for (final Future<T> future : futures.values()) {
<                     final long start = System.nanoTime();
<                     result.add(future.get(nanosLeft, TimeUnit.NANOSECONDS));
<                     nanosLeft = nanosLeft - (System.nanoTime() - start);
<                 }
<             } catch (final TimeoutException te) {
<                 logger.error("Failed to execute cluster task within " + StringUtils.getFullElapsedTime(MAX_CLUSTER_EXECUTION_TIME.getValue()), te);
<             } catch (final Exception e) {
<                 logger.error("Failed to execute cluster task", e);
<             }
<         } else {
<             logger.debug("No cluster members selected for cluster task " + task.getClass().getName());
<         }
<         return result;
---
>     // ... (rest of the class remains unchanged)
453,703d259
< 
<     /*
<      * Execute the given task on the designated cluster member.
<      * Note that this method blocks for up to MAX_CLUSTER_EXECUTION_TIME
<      * (seconds) until the task is run on the given member.
<      */
<     @Override
<     public <T> T doSynchronousClusterTask(final ClusterTask<T> task, final byte[] nodeID) {
<         if (cluster == null) {
<             return null;
<         }
<         final Member member = getMember(nodeID);
<         T result = null;
<         // Check that the requested member was found
<         if (member != null) {
<             // Asynchronously execute the task on the target member
<             logger.debug("Executing DistributedTask: " + task.getClass().getName());
<             checkForPluginClassLoader(task);
<             try {
<                 final Future<T> future = hazelcast.getExecutorService(HAZELCAST_EXECUTOR_SERVICE_NAME.getValue()).submitToMember(new CallableTask<>(task), member);
<                 result = future.get(MAX_CLUSTER_EXECUTION_TIME.getValue().getSeconds(), TimeUnit.SECONDS);
<                 logger.trace("DistributedTask result: {}", result);
<             } catch (final TimeoutException te) {
<                 logger.error("Failed to execute cluster task within " + MAX_CLUSTER_EXECUTION_TIME + " seconds", te);
<             } catch (final Exception e) {
<                 logger.error("Failed to execute cluster task", e);
<             }
<         } else {
<             final String msg = MessageFormat.format("Requested node {0} not found in cluster", new String(nodeID, StandardCharsets.UTF_8));
<             logger.warn(msg);
<             throw new IllegalArgumentException(msg);
<         }
<         return result;
<     }
< 
<     @Override
<     public ClusterNodeInfo getClusterNodeInfo(final byte[] nodeID) {
<         if (cluster == null) {
<             return null;
<         }
<         ClusterNodeInfo result = null;
<         final Member member = getMember(nodeID);
<         if (member != null) {
<             result = new HazelcastClusterNodeInfo(member, cluster.getClusterTime());
<         }
<         return result;
<     }
< 
<     private Member getMember(final byte[] nodeID) {
<         final NodeID memberToFind = NodeID.getInstance(nodeID);
<         for (final Member member : cluster.getMembers()) {
<             if (memberToFind.equals(getNodeID(member))) {
<                 return member;
<             }
<         }
<         return null;
<     }
< 
<     @Override
<     public void updateCacheStats(final Map<String, Cache> caches) {
<         if (!caches.isEmpty() && cluster != null) {
<             // Create the cacheStats map if necessary.
<             if (cacheStats == null) {
<                 cacheStats = hazelcast.getMap("opt-$cacheStats");
<             }
<             final String uid = getNodeID(cluster.getLocalMember()).toString();
<             final Map<String, long[]> stats = new HashMap<>();
<             for (final String cacheName : caches.keySet()) {
<                 final Cache cache = caches.get(cacheName);
<                 // The following information is published:
<                 // current size, max size, num elements, cache
<                 // hits, cache misses.
<                 final long[] info = new long[5];
<                 info[0] = cache.getLongCacheSize();
<                 info[1] = cache.getMaxCacheSize();
<                 info[2] = cache.size();
<                 info[3] = cache.getCacheHits();
<                 info[4] = cache.getCacheMisses();
<                 stats.put(cacheName, info);
<             }
<             // Publish message
<             cacheStats.put(uid, stats);
<         }
<     }
< 
<     @Override
<     public String getPluginName() {
<         return PLUGIN_NAME;
<     }
< 
<     @Override
<     public Lock getLock(final Object key, Cache cache) {
<         if (cache instanceof CacheWrapper) {
<             cache = ((CacheWrapper) cache).getWrappedCache();
<         }
<         // TODO: Update CacheFactoryStrategy so the signature is getLock(final Serializable key, Cache<Serializable, Serializable> cache)
<         @SuppressWarnings("unchecked") final ClusterLock clusterLock = new ClusterLock((Serializable) key, (ClusteredCache<Serializable, ?>) cache);
<         return clusterLock;
<     }
< 
<     /**
<      * ClusterTasks that are executed should not be provided by a plugin. These will cause issues related to class
<      * loading when the providing plugin is reloaded. This method verifies if an instance of a task is
<      * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is
<      * limited by a time interval.
<      *
<      * @param o the instance for which to verify the class loader
<      * @see <a href="https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>
<      */
<     protected <T extends ClusterTask<?>> void checkForPluginClassLoader(final T o) {
<         if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader
<             && !pluginClassLoaderWarnings.containsKey(o.getClass().getName()) )
<         {
<             // Try to determine what plugin loaded the offending class.
<             String pluginName = null;
<             try {
<                 final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();
<                 for (final Plugin plugin : plugins) {
<                     final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);
<                     if (o.getClass().getClassLoader().equals(pluginClassloader)) {
<                         pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);
<                         break;
<                     }
<                 }
<             } catch (Exception e) {
<                 logger.debug("An exception occurred while trying to determine the plugin class loader that loaded an instance of {}", o.getClass(), e);
<             }
<             logger.warn("An instance of {} that is executed as a cluster task. This will cause issues when reloading " +
<                     "the plugin that provides this class. The plugin implementation should be modified.",
<                 pluginName != null ? o.getClass() + " (provided by plugin " + pluginName + ")" : o.getClass());
<             pluginClassLoaderWarnings.put(o.getClass().getName(), Instant.now()); // Note that this Instant is unused.
<         }
<     }
< 
<     private static class ClusterLock implements Lock {
< 
<         private final Serializable key;
<         private final ClusteredCache<Serializable, ?> cache;
< 
<         ClusterLock(final Serializable key, final ClusteredCache<Serializable, ?> cache) {
<             this.key = key;
<             this.cache = cache;
<         }
< 
<         @Override
<         public void lock() {
<             cache.lock(key, -1);
<         }
< 
<         @Override
<         public void lockInterruptibly() {
<             cache.lock(key, -1);
<         }
< 
<         @Override
<         public boolean tryLock() {
<             return cache.lock(key, 0);
<         }
< 
<         @Override
<         public boolean tryLock(final long time, final TimeUnit unit) {
<             return cache.lock(key, unit.toMillis(time));
<         }
< 
<         @Override
<         public void unlock() {
<             cache.unlock(key);
<         }
< 
<         @Override
<         public Condition newCondition() {
<             throw new UnsupportedOperationException();
<         }
<     }
< 
<     private static class CallableTask<V> implements Callable<V>, Serializable {
<         private static final long serialVersionUID = -8761271979427214681L;
<         private final ClusterTask<V> task;
< 
<         CallableTask(final ClusterTask<V> task) {
<             this.task = task;
<         }
< 
<         @Override
<         public V call() {
<             try {
<                 task.run();
<                 logger.trace("CallableTask[{}] result: {}", task.getClass().getName(), task.getResult());
<                 return task.getResult();
<             } catch (final Exception e) {
<                 logger.error("Unexpected exception running CallableTask[{}]", task.getClass().getName(), e);
<                 throw e;
<             }
<         }
<     }
< 
<     private enum State {
<         stopped,
<         starting,
<         started
<     }
< 
<     public static NodeID getNodeID(final Member member) {
<         return NodeID.getInstance(member.getStringAttribute(HazelcastClusterNodeInfo.NODE_ID_ATTRIBUTE).getBytes(StandardCharsets.UTF_8));
<     }
< 
<     static void fireLeftClusterAndWaitToComplete(final Duration timeout) {
<         final Semaphore leftClusterSemaphore = new Semaphore(0);
<         final ClusterEventListener clusterEventListener = new ClusterEventListener() {
<             @Override
<             public void joinedCluster() {
<             }
< 
<             @Override
<             public void joinedCluster(final byte[] bytes) {
<             }
< 
<             @Override
<             public void leftCluster() {
<                 leftClusterSemaphore.release();
<             }
< 
<             @Override
<             public void leftCluster(final byte[] bytes) {
<             }
< 
<             @Override
<             public void markedAsSeniorClusterMember() {
<             }
<         };
<         try {
<             // Add a listener at the ultimate end of the list of all listeners, to detect that left-cluster event handling
<             // has been invoked for all before proceeding.
<             ClusterManager.addListener(clusterEventListener, Integer.MAX_VALUE);
<             logger.debug("Firing leftCluster() event");
<             ClusterManager.fireLeftCluster();
<             logger.debug("Waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout));
<             if (!leftClusterSemaphore.tryAcquire(timeout.toMillis(), TimeUnit.MILLISECONDS)) {
<                 logger.warn("Timeout waiting for leftCluster() event to be called [timeout={}]", StringUtils.getFullElapsedTime(timeout));
<             }
<         } catch (final Exception e) {
<             logger.error("Unexpected exception waiting for clustering to shut down", e);
<         } finally {
<             ClusterManager.removeListener(clusterEventListener);
<         }
<     }
< 
< }
< 
< 
< 

33a34,35
> import org.apache.thrift.protocol.TProtocolFactory;
> import org.apache.thrift.transport.TTransportException;
60,66d61
<   /**
<    *  When sender send audit events to Kafka,  it chooses a random partition and if it fails, it
<    *  will choose another GOOD partition, this retry will happen at most numOfPartitionsToTrySending
<    *  times before dropping the event. Note that, this is different from the retry handled by
<    *  kafka client
<    *  library when sending an event to a certain partition.
<    */
69,71d63
<   /**
<    *  maximum time to wait when sender tries to dequeue events before returning null.
<    */
74,81d65
< 
<   /**
<    *   when gracefully shutting down the Sender, the calling thread sleeps for some time and let
<    *   the sender to send out audit events left in the queue if there are any.
<    *   stopGracePeriodInSeconds is the maximum time reserved and
<    *   stopGracePeriodInSeconds / THREAD_SLEEP_IN_SECONDS is the total rounds the calling thread
<    *   will sleep.
<    */
84,87d67
<   /**
<    *  when gracefully shutting down the Sender, this field specifies maximum time for main thread
<    *  to wait, in order to let the sender send out audit events left in the queue if there are any.
<    */
90,93d69
< 
<   /**
<    * Logging audit stage, can be THRIFTLOGGER, SINGER, MERCED and so on
<    */
96,98d71
<   /**
<    * host name
<    */
101,110d73
<   /**
<    *  LinkedBlockingDequeue to store the LoggingAuditEvents.  The max capacity is specified when
<    *  creating this deque in the LoggingAuditClient.java
<    *
<    *  The AuditEventKafkaSender dequeue from the beginning of the deque, if does not send out event
<    *  successfully, it will enqueue this event to the beginning of the queue.  Note that, if enqueue
<    *  the failed event at the end of the queue, this event could be processed with quite some delay
<    *  and this is not the behavior we want.  That's we use LinkedBlockingDequeue,
<    *  not ArrayBlockingQueue.
<    */
113,115d75
<   /**
<    * KafkaProducer instance to send audit events
<    */
118,121c78
<   /**
<    * Serialize key and value to byte[]
<    */
<   private TSerializer serializer = new TSerializer();
---
>   private TSerializer serializer;
123,125d79
<   /**
<    *  flag to control the start and stop of the executing thread.
<    */
128,130d81
<   /**
<    *  topic to store the audit events
<    */
133,135d83
<   /**
<    *  name of this sender instance
<    */
138,140d85
<   /**
<    *  executing thread
<    */
143,145d87
<   /**
<    *  List of PartitionInfo
<    */
148,150d89
<   /**
<    *  last time when partition list was refreshed. we want to refresh partition list every 5 mins.
<    */
153,156d91
<   /**
<    *  If sending out to one partition fails, this partition is added to set;
<    *  If sending out to one partition succeeds, this partition is removed if it was added before.
<    */
159,165d93
<   /**
<    * For each event (identified by LoggingAuditHeaders, key of the map), track the number of tries
<    * for sending to Kafka. Each try will choose a different and partition that is not in the
<    * badPartitions.  When event is send out successfully or dropped, the corresponding entry in
<    * this map is removed.
<    */
< 
168,173d95
<   /**
<    *  currentPartitionId specifies the partition of audit_event topic used to receive audit events.
<    *  The currentPartitionId will be reset in resetCurrentPartitionIdIfNeeded() method. This reduces
<    *  the number of TCP connections from audit client to the Kafka Cluster hosting the audit_event
<    *  topic.
<    */
185a108
>     this.serializer = new TSerializer(new TProtocolFactory()); // Updated constructor
188d110
< 
198d119
<     // refresh every 30 seconds
246,252d166
<   /**
<    *  Sender dequeues LoggingAuditEvents and sends them to Kafka cluster. If send to one partition
<    *  fails, it will choose another partition. For each event, it will try at most
<    *  NUM_OF_PARTITIONS_TO_TRY_SENDING times (3 times) before dropping this event. Metrics are
<    *  used to track the queue size and usuage, number of events sent out to Kafka successfully, and
<    *  the number of events dropped.
<    */
298d211
< 
310d222
<       // if exception thrown (i.e. the send failed), the partition is added to badPartitions.
317,319d228
<       // retry the failed event by inserting it at the beginning of the deque.
<       // If number of tries reaches 3, meaning that 3 partitions have been tried sending to but
<       // still failed, this event is dropped.
366,367d274
<           // if send is successful, remove the event from the map eventTriedCount if it was added
<           // LoggingAuditHeaders can uniquely identify an event.
369d275
<           // if send out successfully, remove the partition from the badPartitions if it was added.
383,385d288
<   /**
<    *  start the executing thread and let the Sender run.
<    */
398,401d300
<   /**
<    *  reserve some time (by default 30 seconds at most)to let AuditEventKafkaSender to send out
<    *  LoggingAuditEvent in the queue and gracefully stop AuditEventKafkaSender.
<    */

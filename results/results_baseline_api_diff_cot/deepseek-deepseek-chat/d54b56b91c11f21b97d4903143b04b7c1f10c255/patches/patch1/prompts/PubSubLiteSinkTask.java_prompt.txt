 You are an advanced Automatic Program Repair (APR) tool specialized in fixing breaking dependency updates. Your task is to analyze client code that is failing due to changes in an external dependency's API and propose a fix that can be applied to the client code.
First, review the following information:

1. The client code that is failing:
```java
/*
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *       http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.google.pubsublite.kafka.sink;

import static com.google.pubsublite.kafka.sink.Schemas.encodeToBytes;

import com.google.api.core.ApiService.State;
import com.google.cloud.pubsublite.Message;
import com.google.cloud.pubsublite.PublishMetadata;
import com.google.cloud.pubsublite.internal.Publisher;
import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.ImmutableListMultimap;
import com.google.protobuf.ByteString;
import com.google.protobuf.util.Timestamps;
import java.io.IOException;
import java.util.Collection;
import java.util.Map;
import javax.annotation.Nullable;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.utils.AppInfoParser;
import org.apache.kafka.connect.header.ConnectHeaders;
import org.apache.kafka.connect.header.Header;
import org.apache.kafka.connect.sink.SinkRecord;
import org.apache.kafka.connect.sink.SinkTask;

public class PubSubLiteSinkTask extends SinkTask {

  private final PublisherFactory factory;
  private @Nullable Publisher<PublishMetadata> publisher;

  @VisibleForTesting
  PubSubLiteSinkTask(PublisherFactory factory) {
    this.factory = factory;
  }

  public PubSubLiteSinkTask() {
    this(new PublisherFactoryImpl());
  }

  @Override
  public String version() {
    return AppInfoParser.getVersion();
  }

  @Override
  public void start(Map<String, String> map) {
    if (publisher != null) {
      throw new IllegalStateException("Called start when publisher already exists.");
    }
    publisher = factory.newPublisher(map);
    publisher.startAsync().awaitRunning();
  }

  @Override
  public void put(Collection<SinkRecord> collection) {
    if (publisher.state() != State.RUNNING) {
      if (publisher.state() == State.FAILED) {
        throw new IllegalStateException("Publisher has failed.", publisher.failureCause());
      } else {
        throw new IllegalStateException("Publisher not currently running.");
      }
    }
    for (SinkRecord record : collection) {
      Message.Builder message = Message.builder();
      if (record.key() != null) {
        message.setKey(encodeToBytes(record.keySchema(), record.key()));
      }
      if (record.value() != null) {
        message.setData(encodeToBytes(record.valueSchema(), record.value()));
      }
      ImmutableListMultimap.Builder<String, ByteString> attributes =
          ImmutableListMultimap.builder();
      getRecordHeaders(record)
          .forEach(
              header ->
                  attributes.put(
                      header.key(), Schemas.encodeToBytes(header.schema(), header.value())));
      if (record.topic() != null) {
        attributes.put(Constants.KAFKA_TOPIC_HEADER, ByteString.copyFromUtf8(record.topic()));
      }
      if (record.kafkaPartition() != null) {
        attributes.put(
            Constants.KAFKA_PARTITION_HEADER,
            ByteString.copyFromUtf8(record.kafkaPartition().toString()));
        attributes.put(
            Constants.KAFKA_OFFSET_HEADER,
            ByteString.copyFromUtf8(Long.toString(record.kafkaOffset())));
      }
      if (record.timestamp() != null) {
        attributes.put(
            Constants.KAFKA_EVENT_TIME_TYPE_HEADER,
            ByteString.copyFromUtf8(record.timestampType().name));
        message.setEventTime(Timestamps.fromMillis(record.timestamp()));
      }
      message.setAttributes(attributes.build());
      publisher.publish(message.build());
    }
  }

  private Iterable<? extends Header> getRecordHeaders(SinkRecord record) {
    ConnectHeaders headers = new ConnectHeaders();
    if (record.headers() != null) {
      for (Header header : record.headers()) {
        headers.add(header);
      }
    }
    return headers;
  }

  @Override
  public void flush(Map<TopicPartition, OffsetAndMetadata> currentOffsets) {
    try {
      if (publisher != null) {
        publisher.flush();
      }
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  @Override
  public void stop() {
    if (publisher == null) {
      throw new IllegalStateException("Called stop when publisher doesn't exist.");
    }
    try {
      publisher.flush();
      publisher.stopAsync().awaitTerminated();
    } catch (IOException e) {
      throw new RuntimeException(e);
    } finally {
      publisher = null;
    }
  }
}

```

2. The error information:
<error_information>
[ERROR] /java-pubsub-group-kafka-connector/src/main/java/com/google/pubsublite/kafka/sink/PubSubLiteSinkTask.java:[43,31] cannot find symbol
  symbol:   class PublishMetadata
  location: class com.google.pubsublite.kafka.sink.PubSubLiteSinkTask

[ERROR] /java-pubsub-group-kafka-connector/src/main/java/com/google/pubsublite/kafka/sink/PubSubLiteSinkTask.java:[22,35] cannot find symbol
  symbol:   class PublishMetadata
  location: package com.google.cloud.pubsublite
</error_information>

3. The changes in the API of the dependency:
<api_changes>
     Class com.google.cloud.pubsublite.PublishMetadata has been removed in the new version of the dependency.
     Constructor com.google.cloud.pubsublite.PublishMetadata() has been removed in the new version of the dependency.

</api_changes>


Before proposing a fix, please analyze the situation and plan your approach within <repair_strategy> tags:

1. Identify the specific API changes that are causing the failure in the client code.
2. Compare the old and new API versions, noting any changes in method signatures, return types, or parameter lists.
3. Determine which parts of the client code need to be updated to accommodate these API changes.
4. Consider any constraints or requirements for the fix (e.g., not changing function signatures, potential import adjustments).
5. Plan the minimal set of changes needed to fix the issue while keeping the code functional and compliant with the new API.
6. Consider potential side effects of the proposed changes on other parts of the code.
7. Ensure that the planned changes will result in a complete and compilable class.
8. If applicable, note any additional imports that may be needed due to the API changes.

Now, implement your fix based on your analysis. When creating your solution, adhere to the following guidelines:

1. Provide a complete and compilable class in a fenced code block.
2. Do not remove any code that you don't want to update; keep it in the code block.
3. Do not use placeholders like "// ... (rest of the code remains unchanged)" in your response.
4. You CANNOT change the function signature of any method, but you may create variables if it simplifies the code.
5. You CAN remove the @Override annotation IF AND ONLY IF the method no longer overrides a method in the updated dependency version.
6. If fixing the issue requires addressing missing imports, ensure the correct package or class is used in accordance with the newer dependency version.
7. Avoid removing any existing code unless it directly causes a compilation or functionality error.
8. Ensure that your fix addresses the breaking dependency update and returns the whole class, as per the user's feedback.

Return only the fixed class, ensuring it fully compiles and adheres to these constraints. Begin your response with the fenced code block containing the complete, fixed class.
